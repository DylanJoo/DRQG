## Baseline 2
# train_baseline2:
# 	python3 train_baseline.py \
# 	  --model_name_or_path google/flan-t5-${SIZE} \
# 	  --tokenizer_name google/flan-t5-${SIZE} \
# 	  --config_name google/flan-t5-${SIZE} \
# 	  --output_dir models/checkpoints/flan-t5-${SIZE}-extra-prefix \
# 	  --max_p_length 256 \
# 	  --max_q_length 16 \
# 	  --per_device_train_batch_size 4 \
# 	  --m_negative_per_example 2 \
# 	  --m_positive_per_example 2 \
# 	  --learning_rate 1e-4 \
# 	  --evaluation_strategy steps \
# 	  --max_steps 10000 \
# 	  --save_steps 2000 \
# 	  --eval_steps 500 \
# 	  --train_file ${TRAIN_FILE} \
# 	  --baseline_prefix "Generate a question with relevance label <extra_id_{0}> for the passage: {1}" \
# 	  --prefix_tuning true \
# 	  --do_train \
# 	  --do_eval 

# generate_baseline2:
# 	python3 generate.py \
# 	  --model_path models/checkpoints/flan-t5-base-extra-prefix/checkpoint-2000 \
# 	  --model_name google/flan-t5-base \
# 	  --input_jsonl ${EVAL_FILE} \
# 	  --output_jsonl results/baseline2_prefix.jsonl \
# 	  --device cuda:1 \
# 	  --batch_size 8 \
# 	  --max_p_length 256 \
# 	  --num_pred 11 \
# 	  --prefix "Generate a question with relevance label <extra_id_{0}> for the passage: {1}"

# Soft prompt qg baseline
# train_softprompt_d2q:
# 	export CUDA_VISIBLE_DEVICES=1 
# 	python3 train_softprompt.py \
# 	  --model_name_or_path google/flan-t5-large \
# 	  --tokenizer_name google/flan-t5-large \
# 	  --config_name google/flan-t5-large \
# 	  --output_dir models/checkpoints/flan-t5-large-soft-d2q \
# 	  --max_p_length 256 \
# 	  --max_q_length 16 \
# 	  --per_device_train_batch_size 16 \
# 	  --m_positive_per_example 1 \
# 	  --m_negative_per_example 0 \
# 	  --learning_rate 1e-4 \
# 	  --evaluation_strategy steps \
# 	  --max_steps 10000 \
# 	  --save_steps 4000 \
# 	  --eval_steps 500 \
# 	  --train_file ${TRAIN_FILE} \
# 	  --instruction_prompt "Generate a question for the passage: " \
# 	  --do_train \
# 	  --do_eval 

# generate_baseline_d2q:
# 	python3 generate.py \
# 	  --model_path models/checkpoints/flan-t5-large-soft-d2q/checkpoint-4000 \
# 	  --model_name google/flan-t5-large \
# 	  --input_jsonl ${EVAL_FILE} \
# 	  --output_jsonl results/baseline_d2q_prefix.jsonl \
# 	  --device cuda:1 \
# 	  --batch_size 4 \
# 	  --max_p_length 256 \
# 	  --num_pred 11 \
# 	  --instruction_prompt "Generate a question for the passage: " 


# train_baseline:
# 	python3 train_old/train_baseline.py \
# 	  --model_name_or_path google/flan-t5-base  \
# 	  --tokenizer_name google/flan-t5-base \
# 	  --config_name google/flan-t5-base \
# 	  --output_dir models/checkpoint/flan-t5-base-num-prefix \
# 	  --max_p_length 256 \
# 	  --max_q_length 16 \
# 	  --per_device_train_batch_size 8 \
# 	  --per_device_eval_batch_size 8 \
# 	  --m_negative_per_example 2 \
# 	  --m_positive_per_example 2 \
# 	  --learning_rate 1e-4 \
# 	  --evaluation_strategy steps \
# 	  --max_steps 20000 \
# 	  --save_steps 2000 \
# 	  --eval_steps 500 \
# 	  --train_file ${TRAIN_FILE} \
# 	  --baseline_prefix "Generate a question with relevance score {0} for the passage: {1}" \
# 	  --prefix_tuning true \
# 	  --do_train \
# 	  --do_eval 

# train_softprompt_rel_doc:
# 	python3 train_old/train_softprompt_rel_doc.py \
# 	  --model_name_or_path google/flan-t5-base \
# 	  --tokenizer_name google/flan-t5-base \
# 	  --config_name google/flan-t5-base \
# 	  --output_dir models/checkpoint/flan-t5-base-soft-reldoc \
# 	  --max_p_length 256 \
# 	  --max_q_length 16 \
# 	  --per_device_train_batch_size 8 \
# 	  --per_device_eval_batch_size 8 \
# 	  --m_positive_per_example 2 \
# 	  --m_negative_per_example 2 \
# 	  --learning_rate 1e-3 \
# 	  --evaluation_strategy steps \
# 	  --max_steps 20000 \
# 	  --save_steps 5000 \
# 	  --eval_steps 500 \
# 	  --train_file ${TRAIN_FILE} \
# 	  --instruction_prompt "Generate a question based on semantic vectors of the relevance and a document. relevance: " \
# 	  --relevance_prompt "true true true true true true true true true true" \
# 	  --irrelevance_prompt "false false false false false false false false false false" \
# 	  --baseline_prefix "document: {1}" \
# 	  --random_init false \
# 	  --do_train \
# 	  --do_eval
